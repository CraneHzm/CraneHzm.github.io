<!DOCTYPE html>
<html lang="en">
    <meta http-equiv="content-type" content="text/html;charset=utf-8" />
    <head>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
        <title>HOIMotion: Forecasting Human Motion During Human-Object Interactions Using Egocentric 3D Object Bounding Boxes</title>
        <link rel="stylesheet" media="all" href="./index/css/main_v2.css"/>
        <link rel="stylesheet" media="all" href="./hu24_hoimotion/css/owl.carousel.min.css" />
        <link rel="stylesheet" media="all" href="./hu24_hoimotion/css/owl.theme.default.min.css" />
        <link rel="stylesheet" media="all" href="./hu24_hoimotion/css/jquery-ui.min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
        <script src="./hu24_hoimotion/js/jquery-3.4.1.min.js"></script>
        <script src="./hu24_hoimotion/js/jquery-ui.min.js"></script>
        <script src="./hu24_hoimotion/js/fontawesome-5.11.2.js"></script>
        <script src="./hu24_hoimotion/js/main.js"></script>
        <script src="./hu24_hoimotion/js/owl.carousel.min.js"></script>
        <script src="./hu24_hoimotion/js/rot13.js"></script>
		<script src="https://www.w3counter.com/tracker.js?id=150008"></script>
    </head>
    <body class="header header-location">
        <div class="wrapper">
            <!-- header -->
            <div id="unstickyheader" class="unstickyheader">
                <div class="topbar">
                    <div class="container" >
                        
                    </div>
                </div>
            </div>
        </div>
        

        <!-- content -->
        <div class="content">
        <div class="section margin-top-20 margin-bottom-40">
    <div class="container">

        <h3>HOIMotion: Forecasting Human Motion During Human-Object Interactions Using Egocentric 3D Object Bounding Boxes</h3>

        <h4>
        
            <a class="a-int" href="https://cranehzm.github.io/">Zhiming Hu</a>, Zheming Yin, <a class="a-int" href="https://www.hih-tuebingen.de/forschung/unabhaengige-forschungsgruppen/mocom/">Daniel Haeufle</a>, <a class="a-int" href="https://www.imsb.uni-stuttgart.de/team/Schmitt-00006/">Syn Schmitt</a>, <a class="a-int" href="https://www.perceptualui.org/people/bulling/">Andreas Bulling</a>
        </h4>

        <h4>        
            <span class="pub_additional_journal">IEEE Transactions on Visualization and Computer Graphics (TVCG, ISMAR 2024 Journal-track),
        </span>
        <span class="pub_additional_year">2024</span>.
        </h4>

		<h4><span class="pub_award"><i class="fa fa-award"></i> Best Journal Paper Award</span></h4>

        
        <hr>
        <img src="./hu24_hoimotion/image/teaser.png" class="centerContent"><br>
        <i class="centerContent"></i>                    
        

	<h4>Abstract</h4>
	We present HOIMotion â€“ a novel approach for human motion forecasting during human-object interactions that integrates information about past body poses and egocentric 3D object bounding boxes. Human motion forecasting is important in many augmented reality applications but most existing methods have only used past body poses to predict future motion. HOIMotion first uses an encoder-residual graph convolutional network (GCN) and multi-layer perceptrons to extract features from body poses and egocentric 3D object bounding boxes, respectively. Our method then fuses pose and object features into a novel pose-object graph and uses a residual-decoder GCN to forecast future body motion. We extensively evaluate our method on the Aria digital twin (ADT) and MoGaze datasets and show that HOIMotion consistently outperforms state-of-the-art methods by a large margin of up to 8.7% on ADT and 7.2% on MoGaze in terms of mean per joint position error. Complementing these evaluations, we report a human study (N=20) that shows that the improvements achieved by our method result in forecasted poses being perceived as both more precise and more realistic than those of existing methods. Taken together, these results reveal the significant information content available in egocentric 3D object bounding boxes for human motion forecasting and the effectiveness of our method in exploiting this information.
	<hr>

	<h4>Presentation Video</h4>
	<object type='application/x-shockwave-flash' style='width:1024px; height:608px;' data='https://www.youtube.com/v/uRFuOqvKqb4'>
	<param name='movie' value='https://www.youtube.com/v/uRFuOqvKqb4'/>
	</object>        
	<hr>

	<h4>Paper Video</h4>
	<object type='application/x-shockwave-flash' style='width:1024px; height:608px;' data='https://www.youtube.com/v/RaR9g3YlobQ'>
	<param name='movie' value='https://www.youtube.com/v/RaR9g3YlobQ'/>
	</object>        
	<hr>
		
	<h4>Links</h4>
	<div class="pub_links">
					
		<svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><p>Paper: <a class="pub_list" href="./hu24_hoimotion/pdf/hu24_hoimotion.pdf">paper.pdf</a></p>
		<i class="fa fa-file-powerpoint"></i>&nbsp; Slides: <a class="pub_list" href="./hu24_hoimotion/ppt/hu24_hoimotion.pdf">slides.pdf</a></p>
		<i class="fa fa-file-pdf"></i>&nbsp;Supplementary materials: <a class="pub_list" href="./hu24_hoimotion/pdf/hu24_hoimotion_supplementary_material.pdf">supplementary_material.pdf</a></p>		
		<i class="fa fa-code"></i>&nbsp;Code: <a class="a-text-ext" href="https://github.com/CraneHzm/HOIMotion">code</a></p>
	</div>
	
	<hr>

	<h4>BibTeX</h4>

<div class="pub_bibtex bg_grey">@article{hu24hoimotion,
	author={Hu, Zhiming and Yin, Zheming and Haeufle, Daniel and Schmitt, Syn and Bulling, Andreas},
	journal={IEEE Transactions on Visualization and Computer Graphics}, 
	title={HOIMotion: Forecasting Human Motion During Human-Object Interactions Using Egocentric 3D Object Bounding Boxes}, 
	year={2024}}
</div>
    </div>
</div>

        </div>

        <!-- footer -->
        <div id="footer" class="footer-v1">
            
            <div class="copyright custom-copyright">
                <div class="container">
                    <div class="row">
                        <div class="col-md-6">
                            <p>
                                <span class="custom-copyright-container">
                                    Last modified: 27/10/2024
                                </span>
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        
    </body>
</html>