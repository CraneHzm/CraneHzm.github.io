<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="Research progress of user task prediction and algorithm analysis (in Chinese)">
<meta name="author" content="Zhiming Hu">
<title>Research progress of user task prediction and algorithm analysis (in Chinese)</title>
<!-- Bootstrap core CSS -->
<link href="./UserTask/css/bootstrap.min.css" rel="stylesheet">
<!-- Custom styles for this template -->
<link href="./UserTask/css/offcanvas.css" rel="stylesheet">
</head>


<body>
<div class="container">
<div class="jumbotron">
<h2>Research progress of user task prediction and algorithm analysis (in Chinese)</h2>
<p class="abstract">User task prediction for images, videos, and real-world scenarios</p>
<p iclass="authors"><a href="https://cranehzm.github.io/">Zhiming Hu</a>, Sheng Li, and Meng Gai </p>
<p><a class="btn btn-primary" href="./UserTask/pdf/hu21_UserTask.pdf">PDF</a> </p> 
</div>    
	

<hr>
<div>
<h3>Abstract</h3>
<p>
Users’ cognitive behaviors are dramatically influenced by the specific tasks assigned to them. 
Information on users’ tasks can be applied to many areas, such as human behavior analysis and intelligent human-computer interfaces. 
It can be used as the input of intelligent systems and enable the systems to automatically adjust their functions according to different tasks. 
User task prediction refers to the prediction of users’ tasks at hand based on the characteristics of his or her eye movements, the characteristics of scene content, and other related information. 
User task prediction is a popular research topic in vision research, and researchers have proposed many successful task prediction algorithms. 
However, the algorithms proposed in prior works mainly focus on a particular scene, and comparison and analysis are absent for these algorithms. 
This paper presented a review of prior works on task prediction in scenes of images, videos, and real world, and detailed existing task prediction algorithms. 
Based on a real-world task dataset, this paper evaluated the performances of existing algorithms and conducted the corresponding analysis and discussion. 
As such, this work can provide meaningful insights for future works on this important topic. 
</p>
</div>
		
	
<div class="section">
<h3>Related Work</h3>
<hr>
<p>Our related work:</p>
<p><a href="https://cranehzm.github.io/EHTask.html">EHTask: Recognizing User Tasks from Eye and Head Movements in Immersive Virtual Reality</a></p>
<p><a href="https://cranehzm.github.io/EyeFixation.html">Eye Fixation Forecasting in Task-Oriented Virtual Reality</a></p>
<p><a href="https://cranehzm.github.io/FixationNet.html">FixationNet: Forecasting Eye Fixations in Task-Oriented Virtual Environments</a></p>
<p><a href="https://cranehzm.github.io/GazeAnalysis.html">Gaze Analysis and Prediction in Virtual Reality</a></p>
<p><a href="https://cranehzm.github.io/DGaze.html">DGaze: CNN-Based Gaze Prediction in Dynamic Scenes</a></p>    
<p><a href="https://cranehzm.github.io/TemporalContinuity.html">Temporal Continuity of Visual Attention for Future Gaze Prediction in Immersive Virtual Reality</a></p>    
<p><a href="https://cranehzm.github.io/SGaze.html">SGaze: A Data-Driven Eye-Head Coordination Model for Realtime Gaze Prediction</a></p>
</div>
	
	
<h3>Bibtex</h3>
<hr>
<div class="bibtexsection">
@article{hu21_User,
  title = {Research progress of user task prediction and algorithm analysis (in Chinese)},
  author = {Hu, Zhiming and Li, Sheng and Gai, Meng},
  year = {2021},
  journal={Journal of Graphics},
  doi = {http://www.txxb.com.cn/CN/10.11996/JG.j.2095-302X.2021030367},
  volume = {42},
  number = {3},
  pages = {367-375}
}
</div>
	
	
<hr>
<footer>
<p>Send feedback and questions to <a href="https://cranehzm.github.io/">Zhiming Hu</a>.</p>
<p>Thanks to Vincent Sitzmann for his website template. © 2017</p>
</footer>


</div><!--/.container-->
</body></html>