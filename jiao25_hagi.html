<!DOCTYPE html>
<html lang="en">
    <meta http-equiv="content-type" content="text/html;charset=utf-8" />
    <head>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
        <title>HAGI: Head-Assisted Gaze Imputation for Mobile Eye Trackers</title>
        <link rel="stylesheet" media="all" href="./index/css/main_v2.css" />
        <link rel="stylesheet" media="all" href="./jiao25_hagi/css/owl.carousel.min.css" />
        <link rel="stylesheet" media="all" href="./jiao25_hagi/css/owl.theme.default.min.css" />
        <link rel="stylesheet" media="all" href="./jiao25_hagi/css/jquery-ui.min.css" />
        <script src="./jiao25_hagi/js/jquery-3.4.1.min.js"></script>
        <script src="./jiao25_hagi/js/jquery-ui.min.js"></script>
        <script src="./jiao25_hagi/js/fontawesome-5.11.2.js"></script>
        <script src="./jiao25_hagi/js/main.js"></script>
        <script src="./jiao25_hagi/js/owl.carousel.min.js"></script>
        <script src="./jiao25_hagi/js/rot13.js"></script>
		<script src="https://www.w3counter.com/tracker.js?id=150008"></script>
    </head>
    <body class="header header-location">
        <div class="wrapper">
            <!-- header -->
            <div id="unstickyheader" class="unstickyheader">
                <div class="topbar">
                    <div class="container" >
                    </div>
                </div>
            </div>
        </div>
        

        <!-- content -->
        <div class="content">
        <div class="section margin-top-20 margin-bottom-40">
    <div class="container">

        <h3>HAGI: Head-Assisted Gaze Imputation for Mobile Eye Trackers</h3>

        <h4>        
            <a class="a-int" href="https://www.perceptualui.org/people/jiao/">Chuhan Jiao</a>,
            <a class="a-int" href="https://cranehzm.github.io/">Zhiming Hu</a>,
            <a class="a-int" href="https://www.perceptualui.org/people/bulling/">Andreas Bulling</a>
        </h4>
	
        <h4>        
            <span class="pub_additional_journal">Proc. ACM Symposium on User Interface Software and Technology (UIST), </span>         
            <span class="pub_additional_pages">pp. 1–13, </span>       
        <span class="pub_additional_year">2025</span>.
        </h4>
        
		<hr>
		<img src="./jiao25_hagi/image/teaser.png" style="height:400px;width: auto;" class="centerContent"><br>
		<i class="centerContent"></i>
            
        <hr>

        <h4>Abstract</h4>
        Mobile eye tracking plays a vital role in capturing human visual attention across both real-world and extended reality (XR) environments, making it an essential tool for applications ranging from behavioural research to human-computer interaction. However, missing values due to blinks, pupil detection errors, or illumination changes pose significant challenges for further gaze data analysis. To address this challenge, we introduce HAGI – a multi-modal diffusion-based approach for gaze data imputation that, for the first time, uses the integrated head orientation sensors to exploit the inherent correlation between head and eye movements. Our method includes a head-movement feature extraction module alongside a novel hybrid feature fusion mechanism that effectively integrates gaze and head motion features at multiple levels. Additionally, we introduce a tailored loss function to enhance gaze imputation accuracy further. Extensive evaluations on the large-scale Nymeria, Ego-Exo4D, and HOT3D datasets demonstrate that HAGI consistently outperforms conventional interpolation methods and deep learning-based time-series imputation baselines, reducing mean angular error by up to 22%. Furthermore, statistical analyses confirm that HAGI produces gaze velocity distributions that more closely match actual human gaze behaviour than baselines, ensuring more realistic gaze imputations. Our method paves the way for more complete and accurate eye gaze recordings in real-world settings and has significant potential for enhancing gaze-based analysis and interaction across various application domains.				
        <hr>

        <h4>Links</h4>
        <div class="pub_links">                        
		<i class="fa fa-file-pdf"></i><p>Paper: <a class="pub_list" href="./jiao25_hagi/pdf/jiao25_hagi.pdf">paper.pdf</a></p>
        </div>
        <hr>

        
        <h4>BibTeX</h4>

<div class="pub_bibtex bg_grey">@inproceedings{jiao25hagi,
	author = {Jiao, Chuhan and Hu, Zhiming and Bulling, Andreas},
	title = {HAGI: Head-Assisted Gaze Imputation for Mobile Eye Trackers},
	booktitle = {Proc. ACM Symposium on User Interface Software and Technology (UIST)},
	year = {2025},
	pages = {1--13}}
</div>

        
    </div>
</div>

        </div>

        <!-- footer -->
        <div id="footer" class="footer-v1">
            
            <div class="copyright custom-copyright">
                <div class="container">
                    <div class="row">
                        <div class="col-md-6">
                            <p>
                                
                                <span class="custom-copyright-container">
                                    
                                    Last modified: 07/07/2025
                                </span>
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        
    </body>
</html>
